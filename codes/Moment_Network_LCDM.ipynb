{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51e5a69-86d9-4906-a0ab-9f1fecc02947",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecb46c0-d1dc-42a6-b5f0-c73b8e402a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import numpy as np\n",
    "import h5py\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from scipy import stats\n",
    "from numba import cuda\n",
    "from sklearn.model_selection import train_test_split as _train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow_probability import distributions\n",
    "from tensorflow_probability import math\n",
    "from tensorflow_probability import distributions\n",
    "from tensorflow_probability import math as tfpmath\n",
    "\n",
    "# workaround to import pdn and CLR from another forlder while they are not installed\n",
    "import sys\n",
    "sys.path.insert(0,'../ML_tracer_painting/')\n",
    "sys.path.insert(0,'./')\n",
    "\n",
    "#import pdn\n",
    "import clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ae9a05-fbce-412a-afb1-53aac96c71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"sans-serif\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f650b3-2fa2-40ec-8867-e88ec0495dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory_path = \"/home/draco/work/quijote/Pk_LH/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343b993-cc65-4ead-8217-f88b903dd821",
   "metadata": {},
   "source": [
    "# Define couple of useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8dc442-910d-4a1f-ac7b-d27d21a54514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defining loss plot.\n",
    "\n",
    "def plot_loss(histories, ylim=None, logy=False):\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(\n",
    "            np.array(range(len(history.history['val_loss'])))-0.5, \n",
    "            history.history['loss'], \n",
    "            label='loss'\n",
    "        )\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "\n",
    "        if logy:\n",
    "            plt.semilogy()\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim[0], ylim[1])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        print(key)\n",
    "        plt.title(key)\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c8c070-9db7-423d-8fc1-8dbe0ddee87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the available dataset in the train validation and test set\n",
    "\n",
    "def train_val_test_split(\n",
    "        properties,\n",
    "        labels,\n",
    "        val_fraction,\n",
    "        test_fraction,\n",
    "        random_state=1,\n",
    "):\n",
    "    test_size = round(len(properties) * test_fraction)\n",
    "    val_size = round(len(properties) * val_fraction)\n",
    "\n",
    "    train_prop, test_prop, train_lab, test_lab = _train_test_split(\n",
    "          properties, labels, \n",
    "          test_size=test_size, random_state=random_state)\n",
    "\n",
    "    train_prop, val_prop, train_lab, val_lab = _train_test_split(\n",
    "          train_prop, train_lab,\n",
    "          test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    return train_prop, val_prop, test_prop, train_lab, val_lab, test_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca243752-0bdb-4b98-a1db-59bd36a5c737",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load pre-processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ef00f-8123-47d7-8710-9f8009ed5e8c",
   "metadata": {},
   "source": [
    "Load the target variables from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c1f55-f1ba-47ff-a9a5-7848c9a4f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = directory_path+\"Pk_LH/latin_hypercube_params.txt\"\n",
    "\n",
    "labels_van = np.loadtxt(\n",
    "    filename,\n",
    "    skiprows=1\n",
    ")\n",
    "f = open(filename)\n",
    "header = f.readline()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6dec9-7057-448e-b406-8f432792b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names_vanilla = [\n",
    "    \"Omega_m\",\n",
    "    \"Omega_b\",\n",
    "    \"h\",\n",
    "    \"n_s\",\n",
    "    \"sigma_8\",\n",
    "]\n",
    "\n",
    "label_LaTeX_names_vanilla = [\n",
    "    r\"$\\Omega_m$\",\n",
    "    r\"$\\Omega_b$\",\n",
    "    r\"$h$\",\n",
    "    r\"$n_s$\",\n",
    "    r\"$\\sigma_8$\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecc48e-9aa4-40dd-8944-f0a940798f45",
   "metadata": {},
   "source": [
    "Target variables are normalized so that they have mean=0 and std=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f908977-ff02-4fa4-aef0-40cfb6c265aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_van = []\n",
    "means_van = []\n",
    "\n",
    "for i in range(len(labels_van[0])):\n",
    "    s = np.std(labels_van[:,i])\n",
    "    m = np.mean(labels_van[:,i])\n",
    "    labels_van[:,i] = (labels_van[:,i] - m)/s\n",
    "    sigmas_van.append(s)\n",
    "    means_van.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952a1f7-e26d-4733-8e3e-d183080c4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict(\n",
    "        data,\n",
    "        first_feature_index,\n",
    "        val_fraction = 0.2,\n",
    "        test_fraction = 0.2,\n",
    "        random_state = 1,\n",
    "):    \n",
    "    \n",
    "    data_dict = {\n",
    "        \"train\" : {},\n",
    "        \"val\" : {},\n",
    "        \"test\" : {},\n",
    "    }\n",
    "    \n",
    "    lbl = data[:,0:first_feature_index].copy()\n",
    "    ftr = data[:,first_feature_index:].copy()    \n",
    "    \n",
    "    data_dict[\"train\"][\"ftr\"],\\\n",
    "    data_dict[\"val\"][\"ftr\"],\\\n",
    "    data_dict[\"test\"][\"ftr\"],\\\n",
    "    data_dict[\"train\"][\"lbl\"],\\\n",
    "    data_dict[\"val\"][\"lbl\"],\\\n",
    "    data_dict[\"test\"][\"lbl\"] = \\\n",
    "    train_val_test_split(\n",
    "        ftr, lbl,\n",
    "        val_fraction,\n",
    "        test_fraction,\n",
    "        random_state,\n",
    "    )\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f086b-74c1-4d37-8b88-eb8cfd7eaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = []\n",
    "for i in range(2000):\n",
    "    P0.append(np.loadtxt(directory_path+\"Pk_LH/Pk/\"+str(i)+\"/Pk_m_z=0.txt\")[:32,1] ) # The indeces select kmax = 0.2 and [k, Pk]\n",
    "P0 = np.array(P0)\n",
    "\n",
    "data_LH_vanilla = {}\n",
    "data_LH_vanilla[\"P0\"] = np.concatenate(( labels_van, P0 ), axis=1)\n",
    "\n",
    "for x in data_LH_vanilla.keys():\n",
    "    data_LH_vanilla[x] = get_data_dict(np.array(data_LH_vanilla[x]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39678238-d1e6-4993-91f2-42d0d85df6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P0.T)\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2137ef0-2df4-4635-8d91-421407e04739",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068d790-928a-4e00-9c9a-8bd3fa137b6a",
   "metadata": {},
   "source": [
    "Create layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0fe20a-5c37-44ab-8d7b-487e701e6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_properties = data_LH_vanilla[\"P0\"][\"train\"][\"ftr\"]\n",
    "\n",
    "def create_layers(architecture, dropout_rate):\n",
    "\n",
    "    # the features are normalized to have mean=0 and std=1\n",
    "    inputs = Input(shape=training_set_properties.shape[1])\n",
    "    normalize_layer = layers.Normalization()\n",
    "    normalize_layer.adapt(training_set_properties)\n",
    "    norm_inputs = normalize_layer(inputs)\n",
    "    layer = norm_inputs\n",
    "\n",
    "    # Add 3 hidden dense layers with 128 neuron each\n",
    "    # Each followed by a dropout layer\n",
    "    for n_nodes in architecture:\n",
    "        tlayer = layers.Dense(\n",
    "            n_nodes,\n",
    "            activation=\"selu\",\n",
    "            kernel_initializer='he_normal',\n",
    "        )(layer)\n",
    "        layer = layers.Dropout(dropout_rate)(tlayer)\n",
    "\n",
    "    # Add the output layer combining means and sigmas\n",
    "    means = layers.Dense(\n",
    "        5,\n",
    "        activation=\"linear\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(layer)\n",
    "\n",
    "    sigmas = layers.Dense(\n",
    "        5, \n",
    "        activation=\"elu_plus_one\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(layer)\n",
    "\n",
    "    output_layer = layers.Concatenate()([means, sigmas])\n",
    "    \n",
    "    return inputs, output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66606ea1-6ef4-4321-ae72-0317852b43db",
   "metadata": {},
   "source": [
    "Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a485d4f-7729-43cb-aeeb-a0f241c657fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_means_and_sigmas_uncorrelated(y_true, y_pred):\n",
    "    means_pred, sigmas_pred = tf.split(y_pred, num_or_size_splits=2, axis=1)\n",
    "    \n",
    "    y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "    \n",
    "    squared_differences = tf.math.square(y_true - means_pred)\n",
    "    sigmas2_sigma = tf.math.reduce_mean(tf.math.square(squared_differences - tf.math.square(sigmas_pred)), 0)\n",
    "    sigmas2 = tf.math.reduce_mean(squared_differences, 0) \n",
    "\n",
    "    loss = tf.math.reduce_mean(tf.math.log(sigmas2) + tf.math.log(sigmas2_sigma))\n",
    "    #loss = tf.math.reduce_mean(sigmas2 + sigmas2_sigma)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7ea7b-3fe9-49ed-8673-37e9098e256a",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17832cb6-c8b8-4d5e-a4a9-6fdd676e6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs, output_layer):\n",
    "    model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "    model.compile(\n",
    "        loss=mse_means_and_sigmas_uncorrelated,\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=1.e-5),\n",
    "        #optimizer=tf.optimizers.Adam(learning_rate=1.e-3),\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b399f-b5cd-4858-8aea-79bfd2f59b66",
   "metadata": {},
   "source": [
    "Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c8bd3-956c-41ff-85a4-3d04e3854e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 1.e-3\n",
    "clr_triangular = CLR.CyclicLR(#mode='exp_range',\n",
    "                              base_lr=max_lr/4.,\n",
    "                              max_lr=max_lr,\n",
    "                              step_size=3*4, # recommended (2-8) x (training iterations in epoch)\n",
    "                              gamma=0.99994)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30, #The number pavid people that want to do better than 10 but not commit to 100 use.\n",
    "    restore_best_weights=True,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c6257-7ad5-4d31-8e1c-3a90c1406e5b",
   "metadata": {},
   "source": [
    "Define some ancillary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010be30-0bb1-4cfc-b70d-86afc2476a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab0bf5-0bde-4233-a9c8-997a1db4a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_predictions(trueY, predicY, predicE, label='quantity [some units]', numbins=100, title=None):\n",
    "    fig, ax = plt.subplots(ncols=3,sharex=True,figsize=(9,2.8))#6.4,2.8 #6.4,4.8\n",
    "\n",
    "    ax[0].errorbar(\n",
    "        x=trueY[:], y=predicY,\n",
    "        yerr=predicE,\n",
    "        elinewidth=0.5,\n",
    "        linewidth=0,\n",
    "        #bins='log', xscale='log', yscale='log',\n",
    "        #gridsize=numbins\n",
    "    )\n",
    "    extremes = [np.min([trueY, predicY]),np.max([trueY, predicY])]    \n",
    "    ax[0].set_xlabel('True '+label)\n",
    "    ax[0].set_ylabel('Predicted '+label)\n",
    "    ax[0].plot(extremes, extremes, c='k')\n",
    "    ax[0].set_xlim(extremes[0], extremes[1])\n",
    "    ax[0].set_ylim(extremes[0], extremes[1])\n",
    "    ax[0].set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    ymean = np.mean(trueY)\n",
    "    R2 = 1.-np.sum((trueY-predicY)**2) / np.sum((trueY-ymean)**2)\n",
    "    \n",
    "    ax[0].text(0.975, 0.025, r'$R^2$=%.2f'\n",
    "               \"\\n\"\n",
    "               r\"$\\chi^2$=%.2f\" %(R2, np.sum((trueY - predicY)**2/predicE**2)/(len(predicE)-2)),\n",
    "               style='italic', transform=ax[0].transAxes,\n",
    "        bbox={'facecolor': 'white', 'alpha': 0.5, 'pad': 2}, ha=\"right\", va=\"bottom\")\n",
    "    \n",
    "    ax[1].plot(trueY, predicE, marker=\".\", lw=0, markersize=2, alpha=1)\n",
    "    ax[1].set_xlabel('True '+label)\n",
    "    ax[1].set_ylabel('Standard deviation')\n",
    "    ax[1].text(0.975, 0.025, r'$\\langle\\sigma \\rangle$=%.2f'\n",
    "               \"\\n\"\n",
    "               r\"RMSE=%.2f\" %(np.mean(predicE), np.sqrt(np.mean((predicY-trueY)**2))), \n",
    "               style='italic', transform=ax[1].transAxes,\n",
    "               bbox={'facecolor': 'white', 'alpha': 0.5, 'pad': 2},\n",
    "               ha=\"right\", va=\"bottom\")\n",
    "    \n",
    "    ax[2].grid(axis=\"y\",alpha=0.5,ls=\"--\")\n",
    "    \n",
    "    ax[2].plot(trueY, (predicY-trueY)/predicE, marker=\".\", lw=0, markersize=2, alpha=1)\n",
    "    ax[2].set_xlabel('True '+label)\n",
    "    ax[2].set_ylabel(r'Bias [$\\sigma$]')\n",
    "    ax[2].grid(axis=\"y\",alpha=0.5,ls=\"--\")\n",
    "    ax[2].text(0.975, 0.025, r\"$\\langle bias \\rangle$=%.2f\"\n",
    "               \"\\n\"\n",
    "               r\"$\\langle |bias| \\rangle$=%.2f\" % (np.mean((predicY-trueY)/predicE), np.mean(np.abs(predicY-trueY)/predicE)), \n",
    "               style='italic', transform=ax[2].transAxes,\n",
    "               bbox={'facecolor': 'white', 'alpha': 0.5, 'pad': 2},\n",
    "               ha=\"right\", va=\"bottom\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.subplots_adjust(left=0.1, right=0.975, top=0.9, bottom=0.2)\n",
    "        plt.suptitle(title)#, fontdict={'horizontalalignment': \"center\"})\n",
    "    else:\n",
    "        plt.subplots_adjust(left=0.05, right=0.975, top=0.975, bottom=0.2)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc9872-aa77-434a-bd53-fd531f8c6ef0",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2788447-9a6e-4cf1-b5b8-0746db73722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, output_layer = create_layers([32, 32, 32], 0.3)\n",
    "model = create_model(inputs, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e138f0e-3c46-4761-9ea1-0adca5d87233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histories[\"P0\"] = model.fit(\n",
    "    training_set_properties,\n",
    "    data_LH_vanilla[\"P0\"][\"train\"][\"lbl\"],\n",
    "    validation_data=(data_LH_vanilla[\"P0\"][\"train\"][\"ftr\"],\n",
    "                     data_LH_vanilla[\"P0\"][\"train\"][\"lbl\"]),\n",
    "    batch_size=512,\n",
    "    epochs=1000000,\n",
    "    callbacks=[clr_triangular, early_stopping],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1b710-cac4-4efe-b4db-998d1d3bb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(histories)#, logy=True, ylim=[15, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22380335-43d1-4620-9b14-502dffa4cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_LH_vanilla[\"P0\"]\n",
    "data_split = \"test\"\n",
    "predictions = model.predict(data[data_split][\"ftr\"], verbose=0)\n",
    "\n",
    "for j in range(5):\n",
    "    check_predictions(\n",
    "        data[data_split][\"lbl\"][:,j]*sigmas_van[j]+means_van[j],\n",
    "        predictions[:,j]*sigmas_van[j]+means_van[j], \n",
    "        predictions[:,j+5]*sigmas_van[j],\n",
    "        label=label_LaTeX_names_vanilla[j],\n",
    "        title=\"P0\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc58bc-64a1-4758-bfc4-2bcfe53d60ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1ed16-9a18-43fe-bce0-9f441ac4db3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
